# =============================================================================
# LLM Configuration (any OpenAI-compatible server: Ollama, vLLM, etc.)
# =============================================================================
# URL to your local LLM server's OpenAI-compatible endpoint
# Ollama:  http://localhost:11434/v1
# vLLM:    http://localhost:8000/v1
LOCAL_LLM_URL="http://localhost:11434/v1"

# Model name as known by your LLM server
LOCAL_LLM_MODEL="ministral-3:3b"

# API key for your LLM server (Ollama ignores this; other servers may require a real key)
LOCAL_LLM_API_KEY="ollama"

# =============================================================================
# Speech-to-Text
# =============================================================================
# Faster-Whisper model size: tiny.en, small.en, medium.en, large-v3
LOCAL_STT_MODEL="small.en"

# Digital gain applied to microphone input (e.g., 2.0 to double volume)
MIC_GAIN=1.0

# =============================================================================
# Vision
# =============================================================================
# Local vision model (only used with --smolvlm CLI flag)
LOCAL_VISION_MODEL=HuggingFaceTB/SmolVLM2-2.2B-Instruct

# Cache directory for downloaded models
HF_HOME=./cache

# Hugging Face token (optional, falls back to `hf auth login`)
HF_TOKEN=

# =============================================================================
# Profile & Messaging
# =============================================================================
# Assistant personality profile (see src/.../profiles/)
REACHY_MINI_CUSTOM_PROFILE="default"

# Phone number for Signal messaging (with country code, e.g., +1234567890)
SIGNAL_USER_PHONE=
