from __future__ import annotations  # noqa: D100

import logging
from typing import Optional, Tuple

import numpy as np
from huggingface_hub import hf_hub_download
from supervision import Detections
from ultralytics import YOLO

logger = logging.getLogger(__name__)


class HeadTracker:
    """Lightweight head tracker using YOLO for face detection."""

    def __init__(
        self,
        model_repo: str = "AdamCodd/YOLOv11n-face-detection",
        model_filename: str = "model.pt",
        confidence_threshold: float = 0.3,
        device: str = "cpu",
    ) -> None:
        """Initialize YOLO-based head tracker.

        Args:
            model_repo: HuggingFace model repository
            model_filename: Model file name
            confidence_threshold: Minimum confidence for face detection
            device: Device to run inference on ('cpu' or 'cuda')

        """
        self.confidence_threshold = confidence_threshold

        try:
            # Download and load YOLO model
            model_path = hf_hub_download(repo_id=model_repo, filename=model_filename)
            self.model = YOLO(model_path).to(device)
            logger.info(f"YOLO face detection model loaded from {model_repo}")
        except Exception as e:
            logger.error(f"Failed to load YOLO model: {e}")
            raise

    def _select_best_face(self, detections: Detections) -> Optional[int]:
        """Select the best face based on confidence and area (largest face with highest confidence).

        Args:
            detections: Supervision detections object

        Returns:
            Index of best face or None if no valid faces

        """
        if detections.xyxy.shape[0] == 0:
            return None

        # Filter by confidence threshold
        valid_mask = detections.confidence >= self.confidence_threshold
        if not np.any(valid_mask):
            return None

        valid_indices = np.where(valid_mask)[0]

        # Calculate areas for valid detections
        boxes = detections.xyxy[valid_indices]
        areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])

        # Combine confidence and area (weighted towards larger faces)
        confidences = detections.confidence[valid_indices]
        scores = confidences * 0.7 + (areas / np.max(areas)) * 0.3

        # Return index of best face
        best_idx = valid_indices[np.argmax(scores)]
        return best_idx

    def _bbox_to_mp_coords(self, bbox: np.ndarray, w: int, h: int) -> np.ndarray:
        """Convert bounding box center to MediaPipe-style coordinates [-1, 1].

        Args:
            bbox: Bounding box [x1, y1, x2, y2]
            w: Image width
            h: Image height

        Returns:
            Center point in [-1, 1] coordinates

        """
        center_x = (bbox[0] + bbox[2]) / 2.0
        center_y = (bbox[1] + bbox[3]) / 2.0

        # Normalize to [0, 1] then to [-1, 1]
        norm_x = (center_x / w) * 2.0 - 1.0
        norm_y = (center_y / h) * 2.0 - 1.0

        return np.array([norm_x, norm_y], dtype=np.float32)

    def get_eyes(
        self, img: np.ndarray
    ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
        """Get eye positions (approximated from face bbox).

        Note: YOLO only provides face bbox, so we estimate eye positions

        Args:
            img: Input image

        Returns:
            Tuple of (left_eye, right_eye) in [-1, 1] coordinates

        """
        h, w = img.shape[:2]

        # Run YOLO inference
        results = self.model(img, verbose=False)
        detections = Detections.from_ultralytics(results[0])

        # Select best face
        face_idx = self._select_best_face(detections)
        if face_idx is None:
            return None, None

        bbox = detections.xyxy[face_idx]

        # Estimate eye positions from face bbox (approximate locations)
        face_width = bbox[2] - bbox[0]
        face_height = bbox[3] - bbox[1]

        # Eye positions are roughly at 1/3 and 2/3 of face width, 1/3 of face height
        eye_y = bbox[1] + face_height * 0.35
        left_eye_x = bbox[0] + face_width * 0.35
        right_eye_x = bbox[0] + face_width * 0.65

        # Convert to MediaPipe coordinates
        left_eye = np.array(
            [(left_eye_x / w) * 2 - 1, (eye_y / h) * 2 - 1], dtype=np.float32
        )
        right_eye = np.array(
            [(right_eye_x / w) * 2 - 1, (eye_y / h) * 2 - 1], dtype=np.float32
        )

        return left_eye, right_eye

    def get_eyes_from_landmarks(self, face_landmarks) -> Tuple[np.ndarray, np.ndarray]:
        """Compatibility method - YOLO doesn't have landmarks, so we store bbox in the object."""
        if not hasattr(face_landmarks, "_bbox") or not hasattr(
            face_landmarks, "_img_shape"
        ):
            raise ValueError("Face landmarks object missing required attributes")

        bbox = face_landmarks._bbox
        h, w = face_landmarks._img_shape[:2]

        # Estimate eyes from stored bbox
        face_width = bbox[2] - bbox[0]
        face_height = bbox[3] - bbox[1]

        eye_y = bbox[1] + face_height * 0.35
        left_eye_x = bbox[0] + face_width * 0.35
        right_eye_x = bbox[0] + face_width * 0.65

        left_eye = np.array(
            [(left_eye_x / w) * 2 - 1, (eye_y / h) * 2 - 1], dtype=np.float32
        )
        right_eye = np.array(
            [(right_eye_x / w) * 2 - 1, (eye_y / h) * 2 - 1], dtype=np.float32
        )

        return left_eye, right_eye

    def get_eye_center(self, face_landmarks) -> np.ndarray:
        """Get center point between estimated eyes."""
        left_eye, right_eye = self.get_eyes_from_landmarks(face_landmarks)
        return np.mean([left_eye, right_eye], axis=0)

    def get_roll(self, face_landmarks) -> float:
        """Estimate roll from eye positions (will be 0 for YOLO since we estimate symmetric eyes)."""
        left_eye, right_eye = self.get_eyes_from_landmarks(face_landmarks)
        return float(np.arctan2(right_eye[1] - left_eye[1], right_eye[0] - left_eye[0]))

    def get_head_position(
        self, img: np.ndarray
    ) -> Tuple[Optional[np.ndarray], Optional[float]]:
        """Get head position from face detection.

        Args:
            img: Input image

        Returns:
            Tuple of (eye_center [-1,1], roll_angle)

        """
        h, w = img.shape[:2]

        try:
            # Run YOLO inference
            results = self.model(img, verbose=False)
            detections = Detections.from_ultralytics(results[0])

            # Select best face
            face_idx = self._select_best_face(detections)
            if face_idx is None:
                logger.debug("No face detected above confidence threshold")
                return None, None

            bbox = detections.xyxy[face_idx]
            confidence = detections.confidence[face_idx]

            logger.debug(f"Face detected with confidence: {confidence:.2f}")

            # Get face center in [-1, 1] coordinates
            face_center = self._bbox_to_mp_coords(bbox, w, h)

            # Roll is 0 since we don't have keypoints for precise angle estimation
            roll = 0.0

            return face_center, roll

        except Exception as e:
            logger.error(f"Error in head position detection: {e}")
            return None, None

    def cleanup(self):
        """Clean up resources."""
        if hasattr(self, "model"):
            del self.model
            logger.info("YOLO model cleaned up")


class FaceLandmarks:
    """Simple container for face detection results to maintain API compatibility."""

    def __init__(self, bbox: np.ndarray, img_shape: tuple):
        """Initialize with bounding box and image shape."""
        self._bbox = bbox
        self._img_shape = img_shape
